SEMANTIC TOKENIZER

1. De background tokenizer gebruikt een tokenizer om regels te ontleden in woorden met aanhangende stijl. Zie voorbeeld hieronder. De background tokenizer zorgt voor caching. De interface tussen beide is de functie getLineTokens.
2. Deze tokenizer kun je runtime veranderen met setTokenizer. Dit wordt ondersteund door de Purescript wrapper. Het zou dus goed mogelijk moeten zijn om een tokenizer in Purescript te schrijven!
3. Dit opent de mogelijkheid om een tokenizer te baseren op een AST, c.q. contexten en rollen. GetLineTokens blijkt als derde argument het regelnummer mee te geven! 

OPEN VRAAG.
1. Kunnen we ervoor zorgen dat de parser klaar is voordat de tokenizer aangeroepen wordt?

GETTOKENS IN PURESCRIPT WRAPPER
Het lijkt erop dat de Purescript wrapper een andere representatie geeft voor (het resultaat van) getLineTokens. Het is een array van records met alleen een waarde veld; we missen het type.
Echter, de functie BackgroundTokenizer.getTokens levert wel degelijk records met beide velden.

INDENTERING
De functie getNextLineIndent van de mode krijgt de line (tekst, geen index) mee waarvoor bepaald moet worden of de volgende regel moet worden ingevouwen of niet. Deze functie kan de Tokenizer aanroepen.
We zouden dit op basis van de AST kunnen beslissen. Maar ik betwijfel of dat voordelen oplevert. Bovendien hebben we een row nummer nodig om in de AST te kunnen indexeren.

FOLDING
De functie getFoldWidgetRange van de folding module van de mode krijgt de row (index, geen tekst) mee waarvoor bepaald moet worden of erop kan worden ingevouwen of niet. 
Ook hier zouden we op basis van de AST kunnen beslissen of we willen folden, of niet. Maar ik betwijfel of dat voordelen oplevert boven de huidige methode, gebaseerd op reguliere expressies.


Output van getLineTokens( "Zaak Aangifte heef", "start") is:
{
	tokens: [
  {
    "type": "constant.language",
    "value": "Zaak"
  },
  {
    "type": "text",
    "value": " "
  },
  {
    "type": "type",
    "value": "Aangifte"
  },
  {
    "type": "text",
    "value": " "
  },
  {
    "type": "type",
    "value": "heef"
  }
],
	state: "start"

}

HOE KUNNEN WE EEN TOKENIZER MAKEN IN PURESCRIPT?
Tokenizer is momenteel slechts als data gedeclareerd. We zullen aan Ace een object met de functie getTokenizer moeten leveren.
Dat is dus in Purescript een record met dat ene veld, dat dan gebonden moet zijn aan een gewone javascript functie met drie parameters. 
Deze functie moet de Purescript tokenizer functie roepen, die natuurlijk gecurried is.
We kunnen dat record in Purescript construeren en dan 'witwassen' via een foreign call naar het Tokenizer type.
De functie in dat record veranderen we in een gewone javascript functie met drie parameters met de functie mkFn3 uit Data.Function.Uncurried.

Dit is gelukt!

Deze functie moet dan wel de parse tree kunnen benaderen. Dat is dan de tussenrepresentatie in termen van contexten en rollen. Daarin zullen we een administratie van regelnummers moeten voeren, zodat we het aangeboden regelnummer kunnen relateren aan het juiste onderdeel van de tussenrepresentatie. De functie moet dus de root van de tussenrepresentatie weten. Waarschijnlijk moeten we bij het begin van een sessie met een tekst een tokenizer aanmaken met deze waarde als parameter.
